{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T15:36:50.573758Z",
     "start_time": "2023-09-08T15:36:18.441771Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "import shutil\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立簡單的注意力機制\n",
    "- 改變過往特徵單純的平均加總，是可以動態擁有權重，產生注意力的概念！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T15:44:37.192815Z",
     "start_time": "2023-09-08T15:44:37.183839Z"
    }
   },
   "outputs": [],
   "source": [
    "class Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self, k):\n",
    "        super(Attention, self).__init__()\n",
    "        self.k = k\n",
    "        self.a = keras.layers.Dense(units=self.k, activation='softmax')\n",
    "        self.mul = keras.layers.Multiply()\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        attention = self.a(inputs)\n",
    "        return self.mul([inputs, attention])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假設有一個神經網路，其有10個輸入，需要得到動態權重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T15:44:38.037856Z",
     "start_time": "2023-09-08T15:44:37.883270Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 10)]              0         \n",
      "_________________________________________________________________\n",
      "attention (Attention)        (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_dim = 10\n",
    "\n",
    "\n",
    "inputs = keras.Input(shape=(input_dim,))\n",
    "x = Attention(k=input_dim)(inputs)\n",
    "outputs = keras.layers.Dense(units=1, activation='sigmoid')(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T15:46:15.703685Z",
     "start_time": "2023-09-08T15:46:14.624692Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, to_file='attention-network.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AFM注意力機制\n",
    "- 兩兩特徵域注意力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 10), dtype=float64, numpy=\n",
       "array([[1.05899948, 1.05095217, 0.99624332, 0.59168742, 0.70293557,\n",
       "        0.66682034, 0.88348986, 0.77728853, 0.39574051, 0.15802991],\n",
       "       [1.00200586, 0.98686569, 0.83753616, 0.6240536 , 0.60798865,\n",
       "        0.63598126, 0.67242472, 0.62852547, 0.33587043, 0.23567573],\n",
       "       [1.05743909, 1.05018737, 1.00571926, 0.58412897, 0.70784772,\n",
       "        0.66531211, 0.89921627, 0.78727867, 0.39917418, 0.14882557]])>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(np.random.rand(3, 2), np.random.rand(10, 2), transpose_b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class AFMAttentionNet(tf.keras.layers.Layer):\n",
    "    def __init__(self, attn_units):\n",
    "        super(AFMAttentionNet, self).__init__()\n",
    "        # 假设我们使用一个全连接层作为注意力网络的核心\n",
    "        self.attn_dense1 = tf.keras.layers.Dense(attn_units, activation='relu')\n",
    "        self.attn_dense2 = tf.keras.layers.Dense(1, activation=None)  # 输出注意力分数\n",
    "        self.softmax = tf.keras.layers.Softmax(axis=1)\n",
    "\n",
    "    def call(self, embeddings):\n",
    "        # embeddings 应该是一个列表，其中每个元素都是一个特征的嵌入向量\n",
    "        interactions = []\n",
    "        for i in range(len(embeddings)):\n",
    "            for j in range(i+1, len(embeddings)):\n",
    "                # 计算特征向量的交互（element-wise product）\n",
    "                interaction = tf.multiply(embeddings[i], embeddings[j])\n",
    "                interactions.append(interaction)\n",
    "\n",
    "        # 将所有交互向量堆叠成一个矩阵\n",
    "        interactions = tf.stack(interactions, axis=1)  # [batch_size, num_interactions, embedding_dim]\n",
    "\n",
    "        # 计算注意力分数\n",
    "        attn_scores = self.attn_dense1(interactions)\n",
    "        attn_scores = self.attn_dense2(attn_scores)\n",
    "        attn_scores = tf.squeeze(attn_scores, -1)  # [batch_size, num_interactions]\n",
    "        attn_weights = self.softmax(attn_scores)\n",
    "\n",
    "        # 加权求和得到最终的交互表示\n",
    "        weighted_interactions = interactions * tf.expand_dims(attn_weights, axis=-1)\n",
    "        output = tf.reduce_sum(weighted_interactions, axis=1)  # [batch_size, embedding_dim]\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_28 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_29 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_30 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_31 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_32 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_26 (Embedding)        (None, 1, 8)         8000        input_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_27 (Embedding)        (None, 1, 8)         8000        input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_28 (Embedding)        (None, 1, 8)         8000        input_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_29 (Embedding)        (None, 1, 8)         8000        input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_30 (Embedding)        (None, 1, 8)         8000        input_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze (TFOpLambd (None, 8)            0           embedding_26[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze_1 (TFOpLam (None, 8)            0           embedding_27[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze_2 (TFOpLam (None, 8)            0           embedding_28[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze_3 (TFOpLam (None, 8)            0           embedding_29[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze_4 (TFOpLam (None, 8)            0           embedding_30[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "afm_attention_net (AFMAttention (None, 8)            101         tf.compat.v1.squeeze[0][0]       \n",
      "                                                                 tf.compat.v1.squeeze_1[0][0]     \n",
      "                                                                 tf.compat.v1.squeeze_2[0][0]     \n",
      "                                                                 tf.compat.v1.squeeze_3[0][0]     \n",
      "                                                                 tf.compat.v1.squeeze_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 1)            9           afm_attention_net[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 40,110\n",
      "Trainable params: 40,110\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 建立一個 functional AFM 模型\n",
    "def create_AFM_model(num_features, embedding_dim, attn_units):\n",
    "    # 輸入層：每個特征都是一個整數索引\n",
    "    inputs = [tf.keras.Input(shape=(1,), dtype=tf.int32) for _ in range(num_features)]\n",
    "    \n",
    "    # 嵌入層：將每個特征索引轉化為嵌入向量\n",
    "    embeddings = [tf.keras.layers.Embedding(1000, embedding_dim)(inp) for inp in inputs]  # 假定每个特征有1000个可能的值\n",
    "    embeddings = [tf.squeeze(embed, axis=1) for embed in embeddings]  # 去除不必要的维度\n",
    "    \n",
    "    # 注意力和交互層\n",
    "    interactions = AFMAttentionNet(attn_units)(embeddings)\n",
    "    \n",
    "    # 輸出層：此例為回歸任務\n",
    "    output = tf.keras.layers.Dense(1)(interactions)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "    return model\n",
    "\n",
    "# 使用上述函数創建模型\n",
    "model = create_AFM_model(num_features=5, embedding_dim=8, attn_units=10)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 實現一個作用於向量的注意力機制，透過簡單的全連接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAttentionNet(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(SimpleAttentionNet, self).__init__()\n",
    "        self.softmax_layer = tf.keras.layers.Softmax()\n",
    "        self.multiply = tf.keras.layers.Multiply()\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(\n",
    "            shape=(input_shape[-1], 1),\n",
    "            initializer='random_normal',\n",
    "            trainable=True\n",
    "        )\n",
    "    \n",
    "    def call(self, embeddings):\n",
    "        # embeddings: (batch_size, seq, embed_dim)\n",
    "        attn_scores = tf.matmul(embeddings, self.w)  # (batch_size, seq, 1)\n",
    "        attn_scores = tf.squeeze(attn_scores, axis=-1) # (batch_size, seq)\n",
    "        attn_probs = self.softmax_layer(attn_scores)   # (batch_size, seq) (0~1)\n",
    "        \n",
    "        # 為了相乘需要到同樣的形狀\n",
    "        attn_probs = tf.expand_dims(attn_probs, axis=-1) # (batch_size, seq, 1)  # 之後會廣播\n",
    "        print(attn_probs, tf.reduce_sum(attn_probs))#, attn_probs.numpy.sum())\n",
    "        weighted_embeddings = embeddings * attn_probs    # (batch_size, seq, embed_dim)\n",
    "        \n",
    "        output =  tf.reduce_sum(weighted_embeddings, axis=1) # (batch_size, embed_dim)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"simple_attention_net_6/ExpandDims:0\", shape=(None, 10, 1), dtype=float32) Tensor(\"simple_attention_net_6/Sum:0\", shape=(), dtype=float32)\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_39 (InputLayer)        [(None, 10)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_37 (Embedding)     (None, 10, 32)            320000    \n",
      "_________________________________________________________________\n",
      "simple_attention_net_6 (Simp (None, 32)                32        \n",
      "=================================================================\n",
      "Total params: 320,032\n",
      "Trainable params: 320,032\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## 確認是否如同所想\n",
    "\n",
    "inputs = tf.keras.Input(shape=(10,))\n",
    "embeddings = tf.keras.layers.Embedding(input_dim=10000, output_dim=32, input_length=10)(inputs)\n",
    "attn_weighted_embeddings = SimpleAttentionNet()(embeddings)\n",
    "\n",
    "model = keras.Model(inputs, attn_weighted_embeddings)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.09892201]\n",
      " [0.10125554]\n",
      " [0.10042584]\n",
      " [0.0988341 ]\n",
      " [0.10029733]\n",
      " [0.10064111]\n",
      " [0.09915125]\n",
      " [0.09973518]\n",
      " [0.1004338 ]\n",
      " [0.10030389]], shape=(10, 1), dtype=float32) tf.Tensor(1.0, shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([ 0.00633986, -0.00643159,  0.00284408, -0.0027058 ,  0.00566349,\n",
       "       -0.00116355,  0.0145762 , -0.02578114,  0.00711107, -0.02054787],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 測試輸出\n",
    "\n",
    "test_inputs = np.array([i for i in range(1, 1+10)])\n",
    "\n",
    "model(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
